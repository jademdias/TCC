{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jademdias/TCC/blob/main/Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDYsy9tUCT-l"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
        "import tensorflow as tf\n",
        "import xgboost as xgb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBV71Ju3_QQK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import keras\n",
        "from PIL import Image\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEIlu9keBk__"
      },
      "outputs": [],
      "source": [
        "names = [\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"QDA\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3iF-7k-Bm_x"
      },
      "outputs": [],
      "source": [
        "classifiers = [\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fynf4lloB27C"
      },
      "outputs": [],
      "source": [
        "def GenerateDatanoise(X_train_idx):\n",
        "  sig = X_train_idx\n",
        "  signals = [sig]\n",
        "  for i in range(1, 921):\n",
        "    noise = np.random.normal(0, .1, sig.shape)\n",
        "    signals.append(sig + noise)\n",
        "  return signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMpgBrE2CXfr",
        "outputId": "895fb2ba-2b7d-4ac7-c1d7-99ed0f768ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6822, 81) (223793, 8)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/TCC/DATA/emg_all_features_labeled.csv')\n",
        "raw = pd.read_csv('/content/drive/MyDrive/TCC/DATA/index_finger_motion_raw.csv')\n",
        "#print(df.head())\n",
        "print(df.shape, raw.shape)\n",
        "#print(df.describe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:,:80].copy()\n",
        "y = df.iloc[:,80].copy()\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1)\n",
        "\n",
        "print(\"x_train shape\", x_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"x_test shape\", x_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "idxmais = [107, 157, 173, 272, 255]\n",
        "for j in idxmais:\n",
        "  #idxmais = 5   \n",
        "  datanoise = GenerateDatanoise(x_test[j])\n",
        "  for i in range(0, len(datanoise)):\n",
        "    x_train = np.append(x_train, [np.array(datanoise[i])], axis=0)\n",
        "    y_train = np.append(y_train, y_train[j])\n",
        "\n",
        "print(\"X_train shape\", x_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", x_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KybYLF5-majq",
        "outputId": "ca628822-4ecd-46ca-b65b-fdaab55c1786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6822, 80)\n",
            "(6822,)\n",
            "x_train shape (5116, 80)\n",
            "y_train shape (5116,)\n",
            "x_test shape (1706, 80)\n",
            "y_test shape (1706,)\n",
            "X_train shape (9721, 80)\n",
            "y_train shape (9721,)\n",
            "X_test shape (1706, 80)\n",
            "y_test shape (1706,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for name, clf in zip(names, classifiers):\n",
        "  clf.fit(x_train, y_train)\n",
        "  score = clf.score(x_test, y_test)\n",
        "  print(\"Score \", name, \": \", score)\n",
        "  scores.append(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1mIAEI2nurg",
        "outputId": "343e44f8-577c-4168-8a34-d3b420ad108d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score  Decision Tree :  0.6049237983587339\n",
            "Score  Random Forest :  0.5545134818288394\n",
            "Score  Neural Net :  0.8862837045720985\n",
            "Score  AdaBoost :  0.3733880422039859\n",
            "Score  Naive Bayes :  0.4413833528722157\n",
            "Score  QDA :  0.5468933177022274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred1 = classifiers[0].predict(x_test)\n",
        "pred2 = classifiers[1].predict(x_test)\n",
        "pred3 = classifiers[2].predict(x_test)\n",
        "pred4 = classifiers[3].predict(x_test)\n",
        "pred5 = classifiers[4].predict(x_test)\n",
        "pred6 = classifiers[5].predict(x_test)\n",
        "\n",
        "predictions = [pred1, pred2, pred3, pred4, pred5, pred6]"
      ],
      "metadata": {
        "id": "H3Pt-B-dnpjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx= [392, 1453, 863, 827, 712, 1664, 890, 1093, 965, 304, 1082, 571, 1405, 354, 0, 121, 1367, 996, 956, 1510, 1089, 1124, 279, 1659, 703, 1591, 1491, 198, 501, 285, 752, 197, 690, 913, 338, 1337, 1010, 490, 1362, 691, 1000, 806, 1344, 1164, 1489, 342, 814, 591, 1270, 1494, 1386, 1237, 270, 357, 771, 157, 1561, 262, 199, 1244, 706, 494, 787, 251, 446, 1266, 419, 474, 84, 984, 848, 1439, 1095, 1272, 1013, 1334, 755, 1488, 581, 902, 1250, 569, 1033, 897, 654, 180, 300, 1137, 505, 878, 1442, 1589, 55, 217, 602, 1560, 630, 985, 915, 1148, 156, 903, 908, 205, 717, 97, 5, 642, 1622, 1702, 127, 1159, 619, 1246, 674, 1611, 1125, 275, 947, 1257, 343, 74, 1553, 550, 1235, 333, 1185, 1264, 1617, 1133, 576, 1127, 1473, 1011, 200, 644, 436, 653, 1555, 1016, 1200, 427, 1036, 1692, 1514, 1188, 989, 468, 671, 1447, 936, 331, 762, 1197, 522, 26, 101, 761, 273, 534, 800, 1620, 1, 1626, 1449, 1154, 471, 1152, 317, 647, 437, 1421, 765, 1317, 140, 1610, 573, 174, 1508, 58, 149, 103, 373, 1289, 1647, 1590, 582, 146, 944, 669, 601, 1484, 1190, 1460, 134, 1208, 1594, 792, 159, 110, 1143, 696, 1253, 287, 69, 1084, 218, 1071, 496, 721, 565, 559, 1316, 459, 509, 1236, 187, 1406, 648, 1528, 1592, 1055, 1374, 42, 1480, 892, 38, 234, 441, 1121, 960, 1134, 1319, 245, 316, 1427, 1705, 1076, 570, 858, 424, 1167, 898, 1495, 693, 438, 919, 400, 1382, 1169, 962, 710, 1701, 561, 1623, 1322, 306, 1562, 1441, 1359, 790, 1606, 929, 1501, 1513, 1174, 1476, 397, 635, 1255, 356, 1326, 170, 1549, 1020, 971, 1688, 15, 259, 29, 155, 1324, 831, 40, 387, 1345, 836, 1437, 708, 1180, 195, 1615, 453, 652, 132, 564, 493, 1669, 667, 1005, 622, 1273, 337, 1572, 1119, 291, 100, 391, 31, 1168, 188, 1539, 407, 882, 1023, 1207, 605, 141, 314, 1312, 87, 7, 608, 1306, 266, 385, 138, 215, 874, 355, 516, 1261, 1202, 4, 1131, 1048, 181, 1057, 1412, 1258, 675, 976, 950, 420, 1283, 85, 115, 1697, 1521, 1576, 805, 1446, 153, 1224, 1242, 1433, 1420, 1703, 1279, 1274, 757, 1295, 14, 379, 210, 1418, 489, 994, 444, 67, 230, 464, 799, 645, 1645, 303, 311, 833, 176, 926, 290, 1451, 1475, 370, 1265, 49, 1443, 1410, 381, 655, 1192, 81, 409, 428, 775, 835, 497, 1291, 1458, 1294, 1126, 609, 1019, 724, 544, 1357, 801, 321, 1108, 1075, 699, 514, 1149, 672, 1593, 937, 1532, 1333, 506, 758, 1428, 854, 1506, 1444, 1030, 236, 1479, 457, 1485, 498, 289, 723, 1452, 612, 229, 1007, 223, 963, 1654, 1502, 34, 590, 203, 416, 443, 906, 924, 62, 687, 79, 1348, 238, 920, 1039, 1402, 308, 1171, 476, 193, 148, 1643, 1469, 177, 1668, 515, 1399, 521, 711, 430, 64, 637, 369, 93, 788, 1063, 1199, 1336, 923, 618, 192, 1339, 584, 939, 30, 1161, 390, 1552, 943, 404, 372, 1457, 520, 1557, 679, 1305, 876, 467, 1499, 634, 359, 246, 1616, 1276, 1220, 1263, 394, 1123, 617, 701, 1509, 1027, 871, 1525, 1052, 797, 1284, 957, 1017, 485, 991, 811, 299, 551, 1416, 1331, 104, 1392, 952, 1585, 1335, 1612, 1646, 35, 1296, 1435, 214, 326, 216, 731, 812, 1094, 631, 1142, 1456, 1569, 1470, 1293, 1302, 823, 1193, 1551, 607, 759, 1078, 776, 1204, 112, 336, 1092, 1577, 227, 518, 293, 98, 1109, 405, 773, 123, 399, 1176, 695, 1690, 1482, 1249, 432, 1234, 160, 1663, 604, 1644, 533, 82, 1624, 23, 324, 1321, 1454, 575, 1676, 1686, 1559, 168, 1212, 1178, 107, 126, 1209, 1567, 377, 822]\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "R_zBjVlUnzN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultado = []\n",
        "for pred in predictions:\n",
        "  labels = []\n",
        "  preds = []\n",
        "  for i in idx: \n",
        "    labels.append(y_test[i])\n",
        "    preds.append(pred[i])\n",
        "  res = []\n",
        "  for i, j in zip(labels, preds):\n",
        "    if(i == j):\n",
        "      z = 1\n",
        "    else:\n",
        "      z = 0\n",
        "    res.append(z)\n",
        "  resultado.append(res)\n",
        "print(resultado[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwSrBq92n6j9",
        "outputId": "29368287-0618-470f-b6e5-263aa10f3236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colunas = []\n",
        "nitens = 600 \n",
        "for i in range(1, nitens+1):\n",
        "  colunas.append(\"Item.\"+ str(i))\n",
        "print(colunas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A76PwJ2_n8nN",
        "outputId": "af956093-ad30-461d-c8ea-7d5fcb603963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Item.1', 'Item.2', 'Item.3', 'Item.4', 'Item.5', 'Item.6', 'Item.7', 'Item.8', 'Item.9', 'Item.10', 'Item.11', 'Item.12', 'Item.13', 'Item.14', 'Item.15', 'Item.16', 'Item.17', 'Item.18', 'Item.19', 'Item.20', 'Item.21', 'Item.22', 'Item.23', 'Item.24', 'Item.25', 'Item.26', 'Item.27', 'Item.28', 'Item.29', 'Item.30', 'Item.31', 'Item.32', 'Item.33', 'Item.34', 'Item.35', 'Item.36', 'Item.37', 'Item.38', 'Item.39', 'Item.40', 'Item.41', 'Item.42', 'Item.43', 'Item.44', 'Item.45', 'Item.46', 'Item.47', 'Item.48', 'Item.49', 'Item.50', 'Item.51', 'Item.52', 'Item.53', 'Item.54', 'Item.55', 'Item.56', 'Item.57', 'Item.58', 'Item.59', 'Item.60', 'Item.61', 'Item.62', 'Item.63', 'Item.64', 'Item.65', 'Item.66', 'Item.67', 'Item.68', 'Item.69', 'Item.70', 'Item.71', 'Item.72', 'Item.73', 'Item.74', 'Item.75', 'Item.76', 'Item.77', 'Item.78', 'Item.79', 'Item.80', 'Item.81', 'Item.82', 'Item.83', 'Item.84', 'Item.85', 'Item.86', 'Item.87', 'Item.88', 'Item.89', 'Item.90', 'Item.91', 'Item.92', 'Item.93', 'Item.94', 'Item.95', 'Item.96', 'Item.97', 'Item.98', 'Item.99', 'Item.100', 'Item.101', 'Item.102', 'Item.103', 'Item.104', 'Item.105', 'Item.106', 'Item.107', 'Item.108', 'Item.109', 'Item.110', 'Item.111', 'Item.112', 'Item.113', 'Item.114', 'Item.115', 'Item.116', 'Item.117', 'Item.118', 'Item.119', 'Item.120', 'Item.121', 'Item.122', 'Item.123', 'Item.124', 'Item.125', 'Item.126', 'Item.127', 'Item.128', 'Item.129', 'Item.130', 'Item.131', 'Item.132', 'Item.133', 'Item.134', 'Item.135', 'Item.136', 'Item.137', 'Item.138', 'Item.139', 'Item.140', 'Item.141', 'Item.142', 'Item.143', 'Item.144', 'Item.145', 'Item.146', 'Item.147', 'Item.148', 'Item.149', 'Item.150', 'Item.151', 'Item.152', 'Item.153', 'Item.154', 'Item.155', 'Item.156', 'Item.157', 'Item.158', 'Item.159', 'Item.160', 'Item.161', 'Item.162', 'Item.163', 'Item.164', 'Item.165', 'Item.166', 'Item.167', 'Item.168', 'Item.169', 'Item.170', 'Item.171', 'Item.172', 'Item.173', 'Item.174', 'Item.175', 'Item.176', 'Item.177', 'Item.178', 'Item.179', 'Item.180', 'Item.181', 'Item.182', 'Item.183', 'Item.184', 'Item.185', 'Item.186', 'Item.187', 'Item.188', 'Item.189', 'Item.190', 'Item.191', 'Item.192', 'Item.193', 'Item.194', 'Item.195', 'Item.196', 'Item.197', 'Item.198', 'Item.199', 'Item.200', 'Item.201', 'Item.202', 'Item.203', 'Item.204', 'Item.205', 'Item.206', 'Item.207', 'Item.208', 'Item.209', 'Item.210', 'Item.211', 'Item.212', 'Item.213', 'Item.214', 'Item.215', 'Item.216', 'Item.217', 'Item.218', 'Item.219', 'Item.220', 'Item.221', 'Item.222', 'Item.223', 'Item.224', 'Item.225', 'Item.226', 'Item.227', 'Item.228', 'Item.229', 'Item.230', 'Item.231', 'Item.232', 'Item.233', 'Item.234', 'Item.235', 'Item.236', 'Item.237', 'Item.238', 'Item.239', 'Item.240', 'Item.241', 'Item.242', 'Item.243', 'Item.244', 'Item.245', 'Item.246', 'Item.247', 'Item.248', 'Item.249', 'Item.250', 'Item.251', 'Item.252', 'Item.253', 'Item.254', 'Item.255', 'Item.256', 'Item.257', 'Item.258', 'Item.259', 'Item.260', 'Item.261', 'Item.262', 'Item.263', 'Item.264', 'Item.265', 'Item.266', 'Item.267', 'Item.268', 'Item.269', 'Item.270', 'Item.271', 'Item.272', 'Item.273', 'Item.274', 'Item.275', 'Item.276', 'Item.277', 'Item.278', 'Item.279', 'Item.280', 'Item.281', 'Item.282', 'Item.283', 'Item.284', 'Item.285', 'Item.286', 'Item.287', 'Item.288', 'Item.289', 'Item.290', 'Item.291', 'Item.292', 'Item.293', 'Item.294', 'Item.295', 'Item.296', 'Item.297', 'Item.298', 'Item.299', 'Item.300', 'Item.301', 'Item.302', 'Item.303', 'Item.304', 'Item.305', 'Item.306', 'Item.307', 'Item.308', 'Item.309', 'Item.310', 'Item.311', 'Item.312', 'Item.313', 'Item.314', 'Item.315', 'Item.316', 'Item.317', 'Item.318', 'Item.319', 'Item.320', 'Item.321', 'Item.322', 'Item.323', 'Item.324', 'Item.325', 'Item.326', 'Item.327', 'Item.328', 'Item.329', 'Item.330', 'Item.331', 'Item.332', 'Item.333', 'Item.334', 'Item.335', 'Item.336', 'Item.337', 'Item.338', 'Item.339', 'Item.340', 'Item.341', 'Item.342', 'Item.343', 'Item.344', 'Item.345', 'Item.346', 'Item.347', 'Item.348', 'Item.349', 'Item.350', 'Item.351', 'Item.352', 'Item.353', 'Item.354', 'Item.355', 'Item.356', 'Item.357', 'Item.358', 'Item.359', 'Item.360', 'Item.361', 'Item.362', 'Item.363', 'Item.364', 'Item.365', 'Item.366', 'Item.367', 'Item.368', 'Item.369', 'Item.370', 'Item.371', 'Item.372', 'Item.373', 'Item.374', 'Item.375', 'Item.376', 'Item.377', 'Item.378', 'Item.379', 'Item.380', 'Item.381', 'Item.382', 'Item.383', 'Item.384', 'Item.385', 'Item.386', 'Item.387', 'Item.388', 'Item.389', 'Item.390', 'Item.391', 'Item.392', 'Item.393', 'Item.394', 'Item.395', 'Item.396', 'Item.397', 'Item.398', 'Item.399', 'Item.400', 'Item.401', 'Item.402', 'Item.403', 'Item.404', 'Item.405', 'Item.406', 'Item.407', 'Item.408', 'Item.409', 'Item.410', 'Item.411', 'Item.412', 'Item.413', 'Item.414', 'Item.415', 'Item.416', 'Item.417', 'Item.418', 'Item.419', 'Item.420', 'Item.421', 'Item.422', 'Item.423', 'Item.424', 'Item.425', 'Item.426', 'Item.427', 'Item.428', 'Item.429', 'Item.430', 'Item.431', 'Item.432', 'Item.433', 'Item.434', 'Item.435', 'Item.436', 'Item.437', 'Item.438', 'Item.439', 'Item.440', 'Item.441', 'Item.442', 'Item.443', 'Item.444', 'Item.445', 'Item.446', 'Item.447', 'Item.448', 'Item.449', 'Item.450', 'Item.451', 'Item.452', 'Item.453', 'Item.454', 'Item.455', 'Item.456', 'Item.457', 'Item.458', 'Item.459', 'Item.460', 'Item.461', 'Item.462', 'Item.463', 'Item.464', 'Item.465', 'Item.466', 'Item.467', 'Item.468', 'Item.469', 'Item.470', 'Item.471', 'Item.472', 'Item.473', 'Item.474', 'Item.475', 'Item.476', 'Item.477', 'Item.478', 'Item.479', 'Item.480', 'Item.481', 'Item.482', 'Item.483', 'Item.484', 'Item.485', 'Item.486', 'Item.487', 'Item.488', 'Item.489', 'Item.490', 'Item.491', 'Item.492', 'Item.493', 'Item.494', 'Item.495', 'Item.496', 'Item.497', 'Item.498', 'Item.499', 'Item.500', 'Item.501', 'Item.502', 'Item.503', 'Item.504', 'Item.505', 'Item.506', 'Item.507', 'Item.508', 'Item.509', 'Item.510', 'Item.511', 'Item.512', 'Item.513', 'Item.514', 'Item.515', 'Item.516', 'Item.517', 'Item.518', 'Item.519', 'Item.520', 'Item.521', 'Item.522', 'Item.523', 'Item.524', 'Item.525', 'Item.526', 'Item.527', 'Item.528', 'Item.529', 'Item.530', 'Item.531', 'Item.532', 'Item.533', 'Item.534', 'Item.535', 'Item.536', 'Item.537', 'Item.538', 'Item.539', 'Item.540', 'Item.541', 'Item.542', 'Item.543', 'Item.544', 'Item.545', 'Item.546', 'Item.547', 'Item.548', 'Item.549', 'Item.550', 'Item.551', 'Item.552', 'Item.553', 'Item.554', 'Item.555', 'Item.556', 'Item.557', 'Item.558', 'Item.559', 'Item.560', 'Item.561', 'Item.562', 'Item.563', 'Item.564', 'Item.565', 'Item.566', 'Item.567', 'Item.568', 'Item.569', 'Item.570', 'Item.571', 'Item.572', 'Item.573', 'Item.574', 'Item.575', 'Item.576', 'Item.577', 'Item.578', 'Item.579', 'Item.580', 'Item.581', 'Item.582', 'Item.583', 'Item.584', 'Item.585', 'Item.586', 'Item.587', 'Item.588', 'Item.589', 'Item.590', 'Item.591', 'Item.592', 'Item.593', 'Item.594', 'Item.595', 'Item.596', 'Item.597', 'Item.598', 'Item.599', 'Item.600']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[] #certo(1), errado(0)\n",
        "for i in resultado:\n",
        "  data.append(i)\n",
        "\n",
        "df = pd.DataFrame(data, columns = colunas)\n",
        "df.loc[6]=[0]*nitens\n",
        "df.loc[7]=[1]*nitens\n",
        "print(df)\n",
        "df.to_csv('/content/data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX2DawJ_n-qM",
        "outputId": "d41f99be-c012-4c67-8b7a-91ce3cdbbab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Item.1  Item.2  Item.3  Item.4  Item.5  Item.6  Item.7  Item.8  Item.9  \\\n",
            "0       1       0       1       1       0       0       1       1       0   \n",
            "1       0       0       0       0       0       0       0       0       0   \n",
            "2       1       1       1       1       0       1       1       0       0   \n",
            "3       0       0       0       0       0       0       0       0       0   \n",
            "4       1       0       1       1       1       0       0       1       1   \n",
            "5       1       1       1       1       1       1       1       1       1   \n",
            "6       0       0       0       0       0       0       0       0       0   \n",
            "7       1       1       1       1       1       1       1       1       1   \n",
            "\n",
            "   Item.10  ...  Item.591  Item.592  Item.593  Item.594  Item.595  Item.596  \\\n",
            "0        0  ...         1         1         1         1         0         1   \n",
            "1        0  ...         1         1         1         1         1         1   \n",
            "2        1  ...         1         1         1         1         0         1   \n",
            "3        0  ...         1         1         1         1         1         1   \n",
            "4        0  ...         0         0         0         0         0         0   \n",
            "5        1  ...         0         0         0         0         0         0   \n",
            "6        0  ...         0         0         0         0         0         0   \n",
            "7        1  ...         1         1         1         1         1         1   \n",
            "\n",
            "   Item.597  Item.598  Item.599  Item.600  \n",
            "0         1         1         1         1  \n",
            "1         1         1         1         1  \n",
            "2         1         1         1         1  \n",
            "3         1         1         1         1  \n",
            "4         0         0         0         0  \n",
            "5         0         0         0         0  \n",
            "6         0         0         0         0  \n",
            "7         1         1         1         1  \n",
            "\n",
            "[8 rows x 600 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!Rscript /content/drive/MyDrive/TCC/tri.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4T2E6F8oBMS",
        "outputId": "b1278eff-6b35-4c10-8f7a-afbb44be48b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "also installing the dependencies ‘textshaping’, ‘ragg’, ‘pkgdown’\n",
            "\n",
            "trying URL 'https://cran.rstudio.com/src/contrib/textshaping_0.3.6.tar.gz'\n",
            "Content type 'application/x-gzip' length 35722 bytes (34 KB)\n",
            "==================================================\n",
            "downloaded 34 KB\n",
            "\n",
            "trying URL 'https://cran.rstudio.com/src/contrib/ragg_1.2.2.tar.gz'\n",
            "Content type 'application/x-gzip' length 424677 bytes (414 KB)\n",
            "==================================================\n",
            "downloaded 414 KB\n",
            "\n",
            "trying URL 'https://cran.rstudio.com/src/contrib/pkgdown_2.0.6.tar.gz'\n",
            "Content type 'application/x-gzip' length 871371 bytes (850 KB)\n",
            "==================================================\n",
            "downloaded 850 KB\n",
            "\n",
            "trying URL 'https://cran.rstudio.com/src/contrib/devtools_2.4.4.tar.gz'\n",
            "Content type 'application/x-gzip' length 374492 bytes (365 KB)\n",
            "==================================================\n",
            "downloaded 365 KB\n",
            "\n",
            "* installing *source* package ‘textshaping’ ...\n",
            "** package ‘textshaping’ successfully unpacked and MD5 sums checked\n",
            "** using staged installation\n",
            "Package fribidi was not found in the pkg-config search path.\n",
            "Perhaps you should add the directory containing `fribidi.pc'\n",
            "to the PKG_CONFIG_PATH environment variable\n",
            "No package 'fribidi' found\n",
            "Using PKG_CFLAGS=\n",
            "Using PKG_LIBS=-lfreetype -lharfbuzz -lfribidi -lpng\n",
            "--------------------------- [ANTICONF] --------------------------------\n",
            "Configuration failed to find the harfbuzz freetype2 fribidi library. Try installing:\n",
            " * deb: libharfbuzz-dev libfribidi-dev (Debian, Ubuntu, etc)\n",
            " * rpm: harfbuzz-devel fribidi-devel (Fedora, EPEL)\n",
            " * csw: libharfbuzz_dev libfribidi_dev (Solaris)\n",
            " * brew: harfbuzz fribidi (OSX)\n",
            "If harfbuzz freetype2 fribidi is already installed, check that 'pkg-config' is in your\n",
            "PATH and PKG_CONFIG_PATH contains a harfbuzz freetype2 fribidi.pc file. If pkg-config\n",
            "is unavailable you can set INCLUDE_DIR and LIB_DIR manually via:\n",
            "R CMD INSTALL --configure-vars='INCLUDE_DIR=... LIB_DIR=...'\n",
            "-------------------------- [ERROR MESSAGE] ---------------------------\n",
            "<stdin>:1:10: fatal error: hb-ft.h: No such file or directory\n",
            "compilation terminated.\n",
            "--------------------------------------------------------------------\n",
            "ERROR: configuration failed for package ‘textshaping’\n",
            "* removing ‘/usr/local/lib/R/site-library/textshaping’\n",
            "ERROR: dependency ‘textshaping’ is not available for package ‘ragg’\n",
            "* removing ‘/usr/local/lib/R/site-library/ragg’\n",
            "ERROR: dependency ‘ragg’ is not available for package ‘pkgdown’\n",
            "* removing ‘/usr/local/lib/R/site-library/pkgdown’\n",
            "ERROR: dependency ‘pkgdown’ is not available for package ‘devtools’\n",
            "* removing ‘/usr/local/lib/R/site-library/devtools’\n",
            "\n",
            "The downloaded source packages are in\n",
            "\t‘/tmp/Rtmpe0nGrQ/downloaded_packages’\n",
            "Warning messages:\n",
            "1: In install.packages(\"devtools\") :\n",
            "  installation of package ‘textshaping’ had non-zero exit status\n",
            "2: In install.packages(\"devtools\") :\n",
            "  installation of package ‘ragg’ had non-zero exit status\n",
            "3: In install.packages(\"devtools\") :\n",
            "  installation of package ‘pkgdown’ had non-zero exit status\n",
            "4: In install.packages(\"devtools\") :\n",
            "  installation of package ‘devtools’ had non-zero exit status\n",
            "Loading required package: usethis\n",
            "\u001b[?25hSkipping install of 'mirt' from a github remote, the SHA1 (2439a3a9) has not changed since last install.\n",
            "  Use `force = TRUE` to force installation\n",
            "\u001b[?25hLoading required package: stats4\n",
            "Loading required package: lattice\n",
            "Iteration: 2, Log-Lik: -1870.973, Max-Change: 0.00000\n",
            "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h              F1       h2\n",
            "Item.1    0.6848 0.468977\n",
            "Item.2    0.7991 0.638618\n",
            "Item.3    0.6848 0.468977\n",
            "Item.4    0.6848 0.468977\n",
            "Item.5    0.7865 0.618531\n",
            "Item.6    0.7991 0.638618\n",
            "Item.7    0.9128 0.833283\n",
            "Item.8    0.4363 0.190396\n",
            "Item.9    0.7865 0.618531\n",
            "Item.10   0.7991 0.638618\n",
            "Item.11   0.8332 0.694293\n",
            "Item.12   0.4305 0.185355\n",
            "Item.13   0.4305 0.185355\n",
            "Item.14   0.6848 0.468977\n",
            "Item.15   0.6848 0.468977\n",
            "Item.16   0.4363 0.190396\n",
            "Item.17   0.6848 0.468977\n",
            "Item.18   0.6848 0.468977\n",
            "Item.19   0.7882 0.621277\n",
            "Item.20   0.4305 0.185355\n",
            "Item.21   0.7991 0.638618\n",
            "Item.22   0.8293 0.687664\n",
            "Item.23   0.6848 0.468977\n",
            "Item.24   0.4305 0.185355\n",
            "Item.25   0.6848 0.468977\n",
            "Item.26   0.7991 0.638618\n",
            "Item.27   0.6848 0.468977\n",
            "Item.28   0.6848 0.468977\n",
            "Item.29   0.6848 0.468977\n",
            "Item.30   0.6848 0.468977\n",
            "Item.31   0.6848 0.468977\n",
            "Item.32   0.9191 0.844760\n",
            "Item.33   0.4305 0.185355\n",
            "Item.34   0.4305 0.185355\n",
            "Item.35   0.6848 0.468977\n",
            "Item.36   0.7882 0.621277\n",
            "Item.37   0.6848 0.468977\n",
            "Item.38   0.7991 0.638618\n",
            "Item.39   0.8668 0.751320\n",
            "Item.40   0.6848 0.468977\n",
            "Item.41   0.6848 0.468977\n",
            "Item.42   0.6848 0.468977\n",
            "Item.43   0.6848 0.468977\n",
            "Item.44   0.6848 0.468977\n",
            "Item.45   0.4305 0.185355\n",
            "Item.46   0.7865 0.618531\n",
            "Item.47   0.4305 0.185355\n",
            "Item.48   0.8668 0.751320\n",
            "Item.49   0.6848 0.468977\n",
            "Item.50   0.5775 0.333530\n",
            "Item.51   0.6848 0.468977\n",
            "Item.52   0.7865 0.618531\n",
            "Item.53   0.4305 0.185355\n",
            "Item.54   0.4305 0.185355\n",
            "Item.55   0.4305 0.185355\n",
            "Item.56   0.7865 0.618531\n",
            "Item.57   0.4305 0.185355\n",
            "Item.58   0.5693 0.324138\n",
            "Item.59   0.6848 0.468977\n",
            "Item.60   0.5775 0.333530\n",
            "Item.61   0.6848 0.468977\n",
            "Item.62   0.8668 0.751320\n",
            "Item.63   0.6848 0.468977\n",
            "Item.64   0.6848 0.468977\n",
            "Item.65   0.5775 0.333530\n",
            "Item.66   0.4305 0.185355\n",
            "Item.67   0.7991 0.638618\n",
            "Item.68   0.4363 0.190396\n",
            "Item.69   0.7991 0.638618\n",
            "Item.70   0.6848 0.468977\n",
            "Item.71   0.6431 0.413518\n",
            "Item.72   0.4305 0.185355\n",
            "Item.73   0.6848 0.468977\n",
            "Item.74   0.6848 0.468977\n",
            "Item.75   0.7991 0.638618\n",
            "Item.76   0.6848 0.468977\n",
            "Item.77   0.7882 0.621277\n",
            "Item.78   0.5775 0.333530\n",
            "Item.79   0.5175 0.267815\n",
            "Item.80   0.7991 0.638618\n",
            "Item.81   0.5775 0.333530\n",
            "Item.82   0.4305 0.185355\n",
            "Item.83   0.6848 0.468977\n",
            "Item.84   0.5775 0.333530\n",
            "Item.85   0.4305 0.185355\n",
            "Item.86   0.4363 0.190396\n",
            "Item.87   0.6848 0.468977\n",
            "Item.88   0.6848 0.468977\n",
            "Item.89   0.6848 0.468977\n",
            "Item.90   0.6848 0.468977\n",
            "Item.91   0.7991 0.638618\n",
            "Item.92   0.4305 0.185355\n",
            "Item.93   0.6848 0.468977\n",
            "Item.94   0.4305 0.185355\n",
            "Item.95   0.7991 0.638618\n",
            "Item.96   0.5775 0.333530\n",
            "Item.97   0.4305 0.185355\n",
            "Item.98   0.6848 0.468977\n",
            "Item.99   0.7865 0.618531\n",
            "Item.100  0.4305 0.185355\n",
            "Item.101  0.7882 0.621277\n",
            "Item.102  0.8668 0.751320\n",
            "Item.103  0.6848 0.468977\n",
            "Item.104  0.5775 0.333530\n",
            "Item.105  0.6848 0.468977\n",
            "Item.106  0.6474 0.419095\n",
            "Item.107  0.5693 0.324138\n",
            "Item.108  0.5313 0.282234\n",
            "Item.109  0.6474 0.419095\n",
            "Item.110  0.7882 0.621277\n",
            "Item.111  0.9191 0.844760\n",
            "Item.112  0.4493 0.201836\n",
            "Item.113  0.8668 0.751320\n",
            "Item.114  0.5319 0.282955\n",
            "Item.115  0.9128 0.833283\n",
            "Item.116  0.5313 0.282234\n",
            "Item.117  0.7991 0.638618\n",
            "Item.118  0.6848 0.468977\n",
            "Item.119  0.9191 0.844760\n",
            "Item.120  0.9128 0.833283\n",
            "Item.121  0.9128 0.833283\n",
            "Item.122  0.7882 0.621277\n",
            "Item.123  0.9128 0.833283\n",
            "Item.124  0.9277 0.860654\n",
            "Item.125  0.6848 0.468977\n",
            "Item.126  0.5291 0.279920\n",
            "Item.127  0.5693 0.324138\n",
            "Item.128  0.5775 0.333530\n",
            "Item.129  0.5313 0.282234\n",
            "Item.130  0.6848 0.468977\n",
            "Item.131  0.6959 0.484303\n",
            "Item.132  0.5313 0.282234\n",
            "Item.133  0.5313 0.282234\n",
            "Item.134  0.5313 0.282234\n",
            "Item.135  0.9277 0.860654\n",
            "Item.136  0.6848 0.468977\n",
            "Item.137  0.7991 0.638618\n",
            "Item.138  0.8332 0.694293\n",
            "Item.139  0.6848 0.468977\n",
            "Item.140  0.9128 0.833283\n",
            "Item.141  0.7979 0.636572\n",
            "Item.142  0.7991 0.638618\n",
            "Item.143  0.6848 0.468977\n",
            "Item.144  0.9191 0.844760\n",
            "Item.145  0.7979 0.636572\n",
            "Item.146  0.4305 0.185355\n",
            "Item.147  0.6848 0.468977\n",
            "Item.148  0.6848 0.468977\n",
            "Item.149  0.9128 0.833283\n",
            "Item.150  0.9128 0.833283\n",
            "Item.151  0.7991 0.638618\n",
            "Item.152  0.9128 0.833283\n",
            "Item.153  0.9128 0.833283\n",
            "Item.154  0.5319 0.282955\n",
            "Item.155  0.7882 0.621277\n",
            "Item.156  0.6848 0.468977\n",
            "Item.157  0.5049 0.254881\n",
            "Item.158  0.5693 0.324138\n",
            "Item.159  0.9191 0.844760\n",
            "Item.160  0.5313 0.282234\n",
            "Item.161  0.8668 0.751320\n",
            "Item.162  0.9277 0.860654\n",
            "Item.163  0.9277 0.860654\n",
            "Item.164  0.9128 0.833283\n",
            "Item.165  0.5313 0.282234\n",
            "Item.166  0.6848 0.468977\n",
            "Item.167  0.6474 0.419095\n",
            "Item.168  0.9128 0.833283\n",
            "Item.169  0.8332 0.694293\n",
            "Item.170  0.9128 0.833283\n",
            "Item.171  0.6848 0.468977\n",
            "Item.172 -0.3155 0.099535\n",
            "Item.173  0.5693 0.324138\n",
            "Item.174  0.5775 0.333530\n",
            "Item.175  0.6058 0.367014\n",
            "Item.176  0.9128 0.833283\n",
            "Item.177  0.7991 0.638618\n",
            "Item.178  0.9128 0.833283\n",
            "Item.179  0.6848 0.468977\n",
            "Item.180  0.7979 0.636572\n",
            "Item.181  0.9128 0.833283\n",
            "Item.182  0.6848 0.468977\n",
            "Item.183  0.5313 0.282234\n",
            "Item.184  0.5319 0.282955\n",
            "Item.185  0.6848 0.468977\n",
            "Item.186  0.9128 0.833283\n",
            "Item.187  0.6848 0.468977\n",
            "Item.188  0.6848 0.468977\n",
            "Item.189  0.5693 0.324138\n",
            "Item.190  0.6058 0.367014\n",
            "Item.191  0.9128 0.833283\n",
            "Item.192  0.5313 0.282234\n",
            "Item.193  0.6848 0.468977\n",
            "Item.194  0.5313 0.282234\n",
            "Item.195  0.8332 0.694293\n",
            "Item.196  0.8332 0.694293\n",
            "Item.197  0.9128 0.833283\n",
            "Item.198  0.6833 0.466859\n",
            "Item.199  0.8332 0.694293\n",
            "Item.200  0.4305 0.185355\n",
            "Item.201  0.6847 0.468790\n",
            "Item.202  0.6847 0.468790\n",
            "Item.203  0.7991 0.638618\n",
            "Item.204  0.7987 0.637996\n",
            "Item.205  0.7987 0.637996\n",
            "Item.206  0.9277 0.860654\n",
            "Item.207  0.8332 0.694293\n",
            "Item.208  0.9277 0.860654\n",
            "Item.209  0.5231 0.273667\n",
            "Item.210  0.4491 0.201662\n",
            "Item.211  0.5231 0.273667\n",
            "Item.212  0.6847 0.468790\n",
            "Item.213  0.8668 0.751320\n",
            "Item.214  0.4306 0.185438\n",
            "Item.215  0.5231 0.273667\n",
            "Item.216  0.8332 0.694293\n",
            "Item.217  0.7991 0.638618\n",
            "Item.218  0.5231 0.273667\n",
            "Item.219  0.8332 0.694293\n",
            "Item.220  0.8332 0.694293\n",
            "Item.221  0.6847 0.468790\n",
            "Item.222  0.4306 0.185438\n",
            "Item.223  0.6847 0.468790\n",
            "Item.224  0.6847 0.468790\n",
            "Item.225  0.8332 0.694293\n",
            "Item.226  0.7987 0.637996\n",
            "Item.227  0.7987 0.637996\n",
            "Item.228  0.7979 0.636572\n",
            "Item.229  0.5231 0.273667\n",
            "Item.230  0.6847 0.468790\n",
            "Item.231  0.6847 0.468790\n",
            "Item.232  0.6847 0.468790\n",
            "Item.233  0.7987 0.637996\n",
            "Item.234  0.9277 0.860654\n",
            "Item.235  0.5231 0.273667\n",
            "Item.236  0.6847 0.468790\n",
            "Item.237  0.7987 0.637996\n",
            "Item.238  0.6847 0.468790\n",
            "Item.239  0.5231 0.273667\n",
            "Item.240  0.4306 0.185438\n",
            "Item.241  0.8332 0.694293\n",
            "Item.242  0.7987 0.637996\n",
            "Item.243  0.5231 0.273667\n",
            "Item.244  0.6847 0.468790\n",
            "Item.245  0.6847 0.468790\n",
            "Item.246  0.6847 0.468790\n",
            "Item.247  0.6847 0.468790\n",
            "Item.248  0.7987 0.637996\n",
            "Item.249  0.7991 0.638618\n",
            "Item.250  0.8332 0.694293\n",
            "Item.251  0.9277 0.860654\n",
            "Item.252  0.6847 0.468790\n",
            "Item.253  0.7987 0.637996\n",
            "Item.254  0.5693 0.324138\n",
            "Item.255  0.8668 0.751320\n",
            "Item.256  0.9127 0.833112\n",
            "Item.257  0.6847 0.468790\n",
            "Item.258  0.6847 0.468790\n",
            "Item.259  0.9127 0.833112\n",
            "Item.260  0.5693 0.324138\n",
            "Item.261  0.7987 0.637996\n",
            "Item.262  0.6847 0.468790\n",
            "Item.263  0.9127 0.833112\n",
            "Item.264  0.4491 0.201662\n",
            "Item.265  0.6848 0.468977\n",
            "Item.266  0.6847 0.468790\n",
            "Item.267  0.6847 0.468790\n",
            "Item.268  0.6847 0.468790\n",
            "Item.269  0.6847 0.468790\n",
            "Item.270  0.5231 0.273667\n",
            "Item.271  0.6847 0.468790\n",
            "Item.272  0.5693 0.324138\n",
            "Item.273  0.8668 0.751320\n",
            "Item.274  0.7987 0.637996\n",
            "Item.275  0.9191 0.844760\n",
            "Item.276  0.7979 0.636572\n",
            "Item.277  0.8332 0.694293\n",
            "Item.278  0.8332 0.694293\n",
            "Item.279  0.6847 0.468790\n",
            "Item.280  0.5231 0.273667\n",
            "Item.281  0.9191 0.844760\n",
            "Item.282  0.7979 0.636572\n",
            "Item.283  0.8668 0.751320\n",
            "Item.284  0.6847 0.468790\n",
            "Item.285  0.7987 0.637996\n",
            "Item.286  0.6847 0.468790\n",
            "Item.287  0.9277 0.860654\n",
            "Item.288  0.9277 0.860654\n",
            "Item.289  0.6847 0.468790\n",
            "Item.290  0.7987 0.637996\n",
            "Item.291  0.7979 0.636572\n",
            "Item.292  0.6847 0.468790\n",
            "Item.293  0.5231 0.273667\n",
            "Item.294  0.6847 0.468790\n",
            "Item.295  0.8668 0.751320\n",
            "Item.296  0.6847 0.468790\n",
            "Item.297  0.5693 0.324138\n",
            "Item.298  0.6847 0.468790\n",
            "Item.299  0.6847 0.468790\n",
            "Item.300  0.6847 0.468790\n",
            "Item.301  0.5319 0.282955\n",
            "Item.302  0.9128 0.833283\n",
            "Item.303  0.8332 0.694293\n",
            "Item.304  0.9128 0.833283\n",
            "Item.305  0.7991 0.638618\n",
            "Item.306  0.7991 0.638618\n",
            "Item.307  0.6848 0.468977\n",
            "Item.308  0.8106 0.657085\n",
            "Item.309  0.7991 0.638618\n",
            "Item.310  0.9128 0.833283\n",
            "Item.311  0.5693 0.324138\n",
            "Item.312  0.5291 0.279920\n",
            "Item.313  0.9128 0.833283\n",
            "Item.314  0.7991 0.638618\n",
            "Item.315  0.7991 0.638618\n",
            "Item.316  0.5231 0.273667\n",
            "Item.317  0.6848 0.468977\n",
            "Item.318  0.7394 0.546757\n",
            "Item.319  0.7865 0.618531\n",
            "Item.320  0.7991 0.638618\n",
            "Item.321  0.8332 0.694293\n",
            "Item.322  0.9128 0.833283\n",
            "Item.323  0.7865 0.618531\n",
            "Item.324  0.7991 0.638618\n",
            "Item.325  0.6848 0.468977\n",
            "Item.326  0.4305 0.185355\n",
            "Item.327  0.7991 0.638618\n",
            "Item.328  0.6848 0.468977\n",
            "Item.329  0.4363 0.190396\n",
            "Item.330  0.9128 0.833283\n",
            "Item.331  0.9277 0.860654\n",
            "Item.332  0.7991 0.638618\n",
            "Item.333  0.5313 0.282234\n",
            "Item.334  0.4305 0.185355\n",
            "Item.335  0.9128 0.833283\n",
            "Item.336  0.4305 0.185355\n",
            "Item.337  0.9128 0.833283\n",
            "Item.338  0.6848 0.468977\n",
            "Item.339  0.7991 0.638618\n",
            "Item.340  0.4493 0.201836\n",
            "Item.341  0.9191 0.844760\n",
            "Item.342  0.6848 0.468977\n",
            "Item.343  0.9128 0.833283\n",
            "Item.344  0.9128 0.833283\n",
            "Item.345  0.7987 0.637996\n",
            "Item.346  0.6848 0.468977\n",
            "Item.347  0.4305 0.185355\n",
            "Item.348  0.9277 0.860654\n",
            "Item.349  0.6848 0.468977\n",
            "Item.350  0.6058 0.367014\n",
            "Item.351  0.6848 0.468977\n",
            "Item.352  0.6848 0.468977\n",
            "Item.353  0.9128 0.833283\n",
            "Item.354  0.9128 0.833283\n",
            "Item.355  0.4305 0.185355\n",
            "Item.356  0.4493 0.201836\n",
            "Item.357  0.6848 0.468977\n",
            "Item.358  0.4305 0.185355\n",
            "Item.359  0.5231 0.273667\n",
            "Item.360  0.8332 0.694293\n",
            "Item.361  0.9128 0.833283\n",
            "Item.362  0.7991 0.638618\n",
            "Item.363  0.5775 0.333530\n",
            "Item.364  0.7991 0.638618\n",
            "Item.365  0.7991 0.638618\n",
            "Item.366  0.9128 0.833283\n",
            "Item.367  0.7865 0.618531\n",
            "Item.368  0.5231 0.273667\n",
            "Item.369  0.4305 0.185355\n",
            "Item.370  0.6848 0.468977\n",
            "Item.371  0.4363 0.190396\n",
            "Item.372  0.8332 0.694293\n",
            "Item.373  0.4493 0.201836\n",
            "Item.374  0.5319 0.282955\n",
            "Item.375  0.7991 0.638618\n",
            "Item.376  0.9128 0.833283\n",
            "Item.377  0.9128 0.833283\n",
            "Item.378  0.5173 0.267612\n",
            "Item.379  0.7991 0.638618\n",
            "Item.380  0.7553 0.570546\n",
            "Item.381  0.7865 0.618531\n",
            "Item.382  0.0313 0.000979\n",
            "Item.383  0.4493 0.201836\n",
            "Item.384  0.7865 0.618531\n",
            "Item.385  0.5775 0.333530\n",
            "Item.386  0.7991 0.638618\n",
            "Item.387  0.7991 0.638618\n",
            "Item.388  0.7991 0.638618\n",
            "Item.389  0.9128 0.833283\n",
            "Item.390  0.5693 0.324138\n",
            "Item.391  0.4305 0.185355\n",
            "Item.392  0.4493 0.201836\n",
            "Item.393  0.8106 0.657085\n",
            "Item.394  0.6848 0.468977\n",
            "Item.395  0.6848 0.468977\n",
            "Item.396  0.5313 0.282234\n",
            "Item.397  0.4305 0.185355\n",
            "Item.398  0.7979 0.636572\n",
            "Item.399  0.8106 0.657085\n",
            "Item.400  0.5231 0.273667\n",
            "Item.401  0.5318 0.282771\n",
            "Item.402  0.5315 0.282442\n",
            "Item.403  0.5315 0.282442\n",
            "Item.404  0.5318 0.282771\n",
            "Item.405  0.5318 0.282771\n",
            "Item.406  0.8103 0.656551\n",
            "Item.407  0.5318 0.282771\n",
            "Item.408  0.5318 0.282771\n",
            "Item.409  0.7987 0.637996\n",
            "Item.410  0.5318 0.282771\n",
            "Item.411  0.5318 0.282771\n",
            "Item.412  0.7987 0.637996\n",
            "Item.413  0.5049 0.254881\n",
            "Item.414  0.9127 0.833112\n",
            "Item.415  0.4491 0.201662\n",
            "Item.416  0.5315 0.282442\n",
            "Item.417  0.5315 0.282442\n",
            "Item.418  0.5318 0.282771\n",
            "Item.419  0.5315 0.282442\n",
            "Item.420  0.5318 0.282771\n",
            "Item.421  0.5315 0.282442\n",
            "Item.422  0.5318 0.282771\n",
            "Item.423  0.8668 0.751320\n",
            "Item.424  0.5315 0.282442\n",
            "Item.425  0.5693 0.324138\n",
            "Item.426  0.7987 0.637996\n",
            "Item.427  0.5318 0.282771\n",
            "Item.428  0.9127 0.833112\n",
            "Item.429  0.5318 0.282771\n",
            "Item.430  0.9127 0.833112\n",
            "Item.431  0.9127 0.833112\n",
            "Item.432  0.7987 0.637996\n",
            "Item.433  0.9127 0.833112\n",
            "Item.434  0.7987 0.637996\n",
            "Item.435  0.8103 0.656551\n",
            "Item.436  0.5315 0.282442\n",
            "Item.437  0.5693 0.324138\n",
            "Item.438  0.5315 0.282442\n",
            "Item.439  0.4491 0.201662\n",
            "Item.440  0.7987 0.637996\n",
            "Item.441  0.4491 0.201662\n",
            "Item.442  0.5185 0.268858\n",
            "Item.443  0.4491 0.201662\n",
            "Item.444  0.7987 0.637996\n",
            "Item.445  0.9127 0.833112\n",
            "Item.446  0.5318 0.282771\n",
            "Item.447  0.7987 0.637996\n",
            "Item.448  0.7987 0.637996\n",
            "Item.449  0.7987 0.637996\n",
            "Item.450  0.7987 0.637996\n",
            "Item.451 -0.3221 0.103773\n",
            "Item.452  0.5318 0.282771\n",
            "Item.453  0.7987 0.637996\n",
            "Item.454  0.9127 0.833112\n",
            "Item.455  0.5693 0.324138\n",
            "Item.456  0.5693 0.324138\n",
            "Item.457  0.5318 0.282771\n",
            "Item.458  0.7987 0.637996\n",
            "Item.459  0.7987 0.637996\n",
            "Item.460  0.9127 0.833112\n",
            "Item.461  0.7987 0.637996\n",
            "Item.462  0.5693 0.324138\n",
            "Item.463  0.7987 0.637996\n",
            "Item.464  0.9127 0.833112\n",
            "Item.465  0.5185 0.268858\n",
            "Item.466  0.5318 0.282771\n",
            "Item.467  0.9127 0.833112\n",
            "Item.468  0.5318 0.282771\n",
            "Item.469  0.7987 0.637996\n",
            "Item.470  0.8103 0.656551\n",
            "Item.471  0.5693 0.324138\n",
            "Item.472  0.5318 0.282771\n",
            "Item.473  0.9127 0.833112\n",
            "Item.474  0.4491 0.201662\n",
            "Item.475  0.5318 0.282771\n",
            "Item.476  0.7987 0.637996\n",
            "Item.477  0.5315 0.282442\n",
            "Item.478  0.5318 0.282771\n",
            "Item.479  0.7987 0.637996\n",
            "Item.480  0.7987 0.637996\n",
            "Item.481  0.7987 0.637996\n",
            "Item.482  0.5318 0.282771\n",
            "Item.483  0.5318 0.282771\n",
            "Item.484  0.4491 0.201662\n",
            "Item.485  0.7987 0.637996\n",
            "Item.486  0.4491 0.201662\n",
            "Item.487  0.5318 0.282771\n",
            "Item.488  0.5318 0.282771\n",
            "Item.489  0.5318 0.282771\n",
            "Item.490  0.9191 0.844760\n",
            "Item.491  0.5318 0.282771\n",
            "Item.492  0.5318 0.282771\n",
            "Item.493 -0.3221 0.103773\n",
            "Item.494  0.6959 0.484303\n",
            "Item.495  0.5291 0.279920\n",
            "Item.496  0.5318 0.282771\n",
            "Item.497  0.7987 0.637996\n",
            "Item.498  0.5318 0.282771\n",
            "Item.499  0.5318 0.282771\n",
            "Item.500  0.7987 0.637996\n",
            "Item.501  0.5318 0.282771\n",
            "Item.502  0.5315 0.282442\n",
            "Item.503  0.5318 0.282771\n",
            "Item.504  0.5318 0.282771\n",
            "Item.505  0.8103 0.656551\n",
            "Item.506  0.5318 0.282771\n",
            "Item.507  0.5318 0.282771\n",
            "Item.508  0.5318 0.282771\n",
            "Item.509  0.5318 0.282771\n",
            "Item.510  0.5318 0.282771\n",
            "Item.511  0.5318 0.282771\n",
            "Item.512  0.5315 0.282442\n",
            "Item.513  0.5318 0.282771\n",
            "Item.514  0.7987 0.637996\n",
            "Item.515  0.5318 0.282771\n",
            "Item.516  0.5318 0.282771\n",
            "Item.517  0.5318 0.282771\n",
            "Item.518  0.5318 0.282771\n",
            "Item.519  0.4491 0.201662\n",
            "Item.520  0.5318 0.282771\n",
            "Item.521  0.5318 0.282771\n",
            "Item.522  0.5318 0.282771\n",
            "Item.523  0.5318 0.282771\n",
            "Item.524  0.5318 0.282771\n",
            "Item.525 -0.3221 0.103773\n",
            "Item.526  0.5318 0.282771\n",
            "Item.527  0.5318 0.282771\n",
            "Item.528  0.5318 0.282771\n",
            "Item.529  0.5318 0.282771\n",
            "Item.530  0.5318 0.282771\n",
            "Item.531  0.5315 0.282442\n",
            "Item.532  0.5318 0.282771\n",
            "Item.533  0.5318 0.282771\n",
            "Item.534  0.5318 0.282771\n",
            "Item.535  0.5318 0.282771\n",
            "Item.536  0.5318 0.282771\n",
            "Item.537  0.5318 0.282771\n",
            "Item.538  0.5318 0.282771\n",
            "Item.539  0.5318 0.282771\n",
            "Item.540  0.5318 0.282771\n",
            "Item.541  0.5318 0.282771\n",
            "Item.542  0.9127 0.833112\n",
            "Item.543  0.5318 0.282771\n",
            "Item.544  0.5318 0.282771\n",
            "Item.545  0.5318 0.282771\n",
            "Item.546  0.5318 0.282771\n",
            "Item.547  0.5318 0.282771\n",
            "Item.548  0.5318 0.282771\n",
            "Item.549  0.5318 0.282771\n",
            "Item.550  0.5315 0.282442\n",
            "Item.551  0.5318 0.282771\n",
            "Item.552  0.5318 0.282771\n",
            "Item.553  0.5318 0.282771\n",
            "Item.554  0.5318 0.282771\n",
            "Item.555  0.5318 0.282771\n",
            "Item.556  0.5318 0.282771\n",
            "Item.557  0.5318 0.282771\n",
            "Item.558  0.5315 0.282442\n",
            "Item.559  0.5318 0.282771\n",
            "Item.560  0.5318 0.282771\n",
            "Item.561  0.5318 0.282771\n",
            "Item.562  0.5318 0.282771\n",
            "Item.563  0.5318 0.282771\n",
            "Item.564  0.5318 0.282771\n",
            "Item.565  0.5318 0.282771\n",
            "Item.566  0.5318 0.282771\n",
            "Item.567  0.5318 0.282771\n",
            "Item.568  0.5318 0.282771\n",
            "Item.569  0.5318 0.282771\n",
            "Item.570  0.5318 0.282771\n",
            "Item.571  0.5318 0.282771\n",
            "Item.572  0.5318 0.282771\n",
            "Item.573  0.5318 0.282771\n",
            "Item.574  0.5318 0.282771\n",
            "Item.575  0.9127 0.833112\n",
            "Item.576  0.5318 0.282771\n",
            "Item.577  0.9191 0.844760\n",
            "Item.578  0.5318 0.282771\n",
            "Item.579  0.5318 0.282771\n",
            "Item.580  0.5318 0.282771\n",
            "Item.581  0.5318 0.282771\n",
            "Item.582  0.5318 0.282771\n",
            "Item.583  0.5318 0.282771\n",
            "Item.584  0.5318 0.282771\n",
            "Item.585  0.5318 0.282771\n",
            "Item.586  0.9127 0.833112\n",
            "Item.587  0.5318 0.282771\n",
            "Item.588  0.5318 0.282771\n",
            "Item.589  0.5318 0.282771\n",
            "Item.590  0.5315 0.282442\n",
            "Item.591  0.5318 0.282771\n",
            "Item.592  0.5318 0.282771\n",
            "Item.593  0.5318 0.282771\n",
            "Item.594  0.5318 0.282771\n",
            "Item.595 -0.3221 0.103773\n",
            "Item.596  0.5318 0.282771\n",
            "Item.597  0.5318 0.282771\n",
            "Item.598  0.5318 0.282771\n",
            "Item.599  0.5318 0.282771\n",
            "Item.600  0.5318 0.282771\n",
            "\n",
            "SS loadings:  280.528 \n",
            "Proportion Var:  0.468 \n",
            "\n",
            "Factor correlations: \n",
            "\n",
            "   F1\n",
            "F1  1\n",
            "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25hnull device \n",
            "          1 \n",
            "\u001b[?25h\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coef = pd.read_csv('/content/coef.csv')"
      ],
      "metadata": {
        "id": "GvX0SjoCoD2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatar(coef): \n",
        "  nitens = 600\n",
        "  ncoef = 4\n",
        "  totalvalues = nitens * ncoef\n",
        "  \n",
        "  a = []\n",
        "  for i in range(0, totalvalues, 4):\n",
        "    a.append(coef.iloc[i][1]) \n",
        "  b = []\n",
        "  for i in range(1, totalvalues, 4):\n",
        "    b.append(coef.iloc[i][1]) \n",
        "  c = []\n",
        "  for i in range(2, totalvalues, 4):\n",
        "    c.append(coef.iloc[i][1])\n",
        "  d = [] \n",
        "  for i in range(3, totalvalues, 4):\n",
        "    d.append(coef.iloc[i][1]) \n",
        "\n",
        "  df = pd.DataFrame({'itens': range(1, nitens + 1 ),\n",
        "                   'a': a,\n",
        "                   'b': b,\n",
        "                   'c': c,\n",
        "                   'd': d\n",
        "                   })\n",
        "  return df"
      ],
      "metadata": {
        "id": "7bDaBwAnoF9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = formatar(coef)"
      ],
      "metadata": {
        "id": "BQT-eqQjoIE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/idx.csv', index=False)"
      ],
      "metadata": {
        "id": "r4mJKKycoKAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df['itens'] == 367)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "dHKPIlyQMx70",
        "outputId": "f2d04fae-9069-49b9-c096-0cadb76d9123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     itens         a         b         c         d\n",
              "366    367  1.703475  2.599586  0.009896  0.857466"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90fd926f-3fa1-420b-8953-fa46887d1379\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itens</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>367</td>\n",
              "      <td>1.703475</td>\n",
              "      <td>2.599586</td>\n",
              "      <td>0.009896</td>\n",
              "      <td>0.857466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90fd926f-3fa1-420b-8953-fa46887d1379')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90fd926f-3fa1-420b-8953-fa46887d1379 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90fd926f-3fa1-420b-8953-fa46887d1379');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfa_ordenado = df.sort_values(by='a', ascending=False)\n",
        "dfb_ordenado = df.sort_values(by='b', ascending=False)\n",
        "dfc_ordenado = df.sort_values(by='c', ascending=False)\n",
        "\n",
        "dfc_ordenado.loc[(dfc_ordenado['itens'] == 107)]"
      ],
      "metadata": {
        "id": "S_mlVOOPoMM-",
        "outputId": "e3b81f1a-9c63-41b1-8954-5471d58ba047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     itens       a          b         c         d\n",
              "106    107  0.1573  26.802425  0.249582  0.599045"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1978c5da-a32a-45c8-b231-2b6ec95fe00b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itens</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>107</td>\n",
              "      <td>0.1573</td>\n",
              "      <td>26.802425</td>\n",
              "      <td>0.249582</td>\n",
              "      <td>0.599045</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1978c5da-a32a-45c8-b231-2b6ec95fe00b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1978c5da-a32a-45c8-b231-2b6ec95fe00b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1978c5da-a32a-45c8-b231-2b6ec95fe00b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tcLSELeat6eWOs-yuixxR8JNIbWAdvv9",
      "authorship_tag": "ABX9TyNnqUsUMlGBHjl6oTyzbM03",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}